{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor turbulence flow\n",
    "In this notebook I recompute some results of \\cite{LarK2017} and play with tensors.\n",
    "\n",
    "#### Why are tensors interesting for me ?\n",
    "Storing and handling flow data can be challenging especially in the purpose of control and optimization. \n",
    "Data can depend on spatial and temporal dimensions as well as special parameters dependent on the optimization problem.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "\n",
    "_repo_root = os.getcwd()\n",
    "if not os.path.isdir(os.path.join(_repo_root, \"torchTT\")):\n",
    "    _repo_root = os.path.abspath(os.path.join(_repo_root, \"..\"))\n",
    "_torchtt_path = os.path.join(_repo_root, \"torchTT\")\n",
    "if _torchtt_path not in sys.path:\n",
    "    sys.path.insert(0, _torchtt_path)\n",
    "\n",
    "import torchtt\n",
    "\n",
    "\n",
    "def tt_datasize(tt):\n",
    "    return sum(int(c.numel()) for c in tt.cores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple 1D sinusoidal example\n",
    "\n",
    "The first example is 1 dimensional sinusoidal function:\n",
    "\n",
    "\\begin{equation}\\label{eq:0Dfunction}\n",
    "    f_1(x)=3.125\\sin(x)\\sin(2x)\\sin(4x) \\qquad\\qquad\\quad x \\in [0,2\\pi]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nx = int(2**14) # spatial domain\n",
    "Lx = 2*pi # domain size\n",
    "\n",
    "x = linspace(0, Lx, Nx) # spatial grid point\n",
    "\n",
    "# funnction values\n",
    "f1 = 3.125 * sin(x) * sin(2*x) * sin(4*x)\n",
    "\n",
    "plt.plot(x,f1)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f_1(x)$\")\n",
    "plt.xticks([0,pi,2*pi],(\"0\",\"$\\pi$\",\"$2\\pi$\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = f1.reshape(2,2,-1)\n",
    "\n",
    "f, ax = plt.subplots(1,2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[0].plot(g[i,j], label=str((i,j)))\n",
    "ax[0].legend()\n",
    "\n",
    "# note that g[i,j,k] == f1[Nx/2*i + Nx/4*j + k]\n",
    "assert np.all(f1[:Nx//4] == g[0,0])\n",
    "ax[1].plot(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is stored with $N_x=2^{14}$ grid points (lattice spacing $\\Delta x$) in an array:\n",
    "\\begin{equation*}\n",
    "     X_1[n]=f_1(n\\Delta x) \\qquad\\qquad n=1\\dots N_x\n",
    "\\end{equation*}\n",
    "resulting in $\\mathcal{O}(N_x)$ storage.\n",
    "Lets reshape into a Tensor of order 3:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = np.reshape(f1, (2, 2, int(Nx/4)))\n",
    "\n",
    "# cast to tensor\n",
    "T1 = torch.tensor(Array, dtype=torch.float64)\n",
    "\n",
    "# make a Tensor Train out of the normal Tensor\n",
    "T1_TT = torchtt.TT(T1)\n",
    "\n",
    "# what is the error in full Format\n",
    "T1_TT = T1_TT.round(1e-4)\n",
    "T1_tilde = T1_TT.full()\n",
    "print(\"TTrank\", T1_TT.R)\n",
    "print(\"Rel_err =\", torch.linalg.norm(T1 - T1_tilde) / torch.linalg.norm(T1))\n",
    "print(\"storage compression:\", tt_datasize(T1_TT) / Nx, \"\n",
    "\")\n",
    "\n",
    "# construct its inner ranks via HOSVD (rounding)\n",
    "T1_TT = T1_TT.round(1e-3)\n",
    "T1_tilde = T1_TT.full()\n",
    "\n",
    "# and output the error of the low-rank approximation\n",
    "print(\"TTrank\", T1_TT.R)\n",
    "print(\"Rel_err =\", torch.linalg.norm(T1 - T1_tilde) / torch.linalg.norm(T1))\n",
    "print(\"storage compression:\", tt_datasize(T1_TT) / Nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchTT does not provide graph drawing; show core shapes instead.\n",
    "print([c.shape for c in T1_TT.cores])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 order Tensor $T_1[n_1,n_2,n_3]$ is approximated \\textbf{\"exactly\"}  for TTrank $\\ge 2$ (cited from section 3.1 at p. 4) by:\n",
    "\n",
    "\\begin{equation}\\label{eq:T3}\n",
    "    T_1[n_1,n_2,n_3] \\approx \\sum_{i=1,j=1,2}U_1[n_1,i]U_2[i,n_2,j]U_3[j,n3]\n",
    "\\end{equation}\n",
    "This is not true as we see from the relative error in the Frobenius norm above. Only for TTrank = 4 the Tensor is \\textit{\"approximated exactly\"} (rel err $\\approx 10^{-15}$). \n",
    "\n",
    "Let's have a look at the matrices in the TTrain:\n",
    "\\begin{align*}\n",
    "    U_1 &= \\frac{1}{\\sqrt{2}}\n",
    "        \\begin{pmatrix}\n",
    "            -1 & 1\n",
    "        \\end{pmatrix} &\n",
    "    U_2 &= \\frac{1}{\\sqrt{2}}\n",
    "        \\begin{pmatrix}\n",
    "            -1 & 1 \\\\\n",
    "             1 & 1\n",
    "        \\end{pmatrix}&\n",
    "     U_3 &= \\begin{pmatrix}\n",
    "            * & \\cdots & * \\\\\n",
    "            * & \\cdots & * \n",
    "            \\end{pmatrix} \\in \\mathbb{R}^{2\\times N_x/4}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate components of the Tensor\n",
    "U1 = T1_TT.cores[0]\n",
    "U2 = T1_TT.cores[1]\n",
    "U3 = T1_TT.cores[2]\n",
    "\n",
    "print(\"U_1 = \", U1.detach().cpu().numpy(),\"\n",
    "\")\n",
    "print(\"U_2 = \",U2.detach().cpu().numpy(),\"\n",
    "\")\n",
    "\n",
    "fnew = U3.detach().cpu().numpy()\n",
    "for i in range(size(fnew,0)):\n",
    "    plt.plot(fnew[i,:])\n",
    "\n",
    "plt.title('$U_3$')\n",
    "plt.tick_params(labelbottom=False)\n",
    "plt.xlabel('$x$')\n",
    "plt.legend((\"1. row\",\"2. row\"))\n",
    "ap = U3.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TTapprox_fun(fun, order, TTrank, threshold=1e-14, orig=None):\n",
    "    # Approximate fun with a tensor train of a certain order.\n",
    "    Nx = size(fun, 0)  # Number of grid points\n",
    "    order = order - 1\n",
    "\n",
    "    # Reshape array to tensor dimensions\n",
    "    A = reshape(fun, np.append([2] * order, int(Nx / 2**order)))\n",
    "    TTrain = torchtt.TT(torch.tensor(A, dtype=torch.float64), eps=threshold, rmax=TTrank)\n",
    "\n",
    "    # compare Tensortrain with original data\n",
    "    Ttilde = TTrain.full().detach().cpu().numpy()\n",
    "    fun_tilde = reshape(Ttilde, -1)\n",
    "\n",
    "    # calculate relative error\n",
    "    if orig is not None:\n",
    "        err_euclid = norm(fun_tilde - orig) / norm(orig)\n",
    "    else:\n",
    "        err_euclid = norm(fun_tilde - fun) / norm(fun)\n",
    "    err_frob = np.linalg.norm(A - Ttilde) / np.linalg.norm(A)\n",
    "    compress_factor = tt_datasize(TTrain) / Nx\n",
    "\n",
    "    return err_euclid, compress_factor, TTrain, fun_tilde, err_frob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sinusoid(fun,TTrank=2,order=3):\n",
    "    error, compress_factor, TTrain, fun_tilde, err_frob= TTapprox_fun(fun,order,TTrank,1e-14)\n",
    "    plt.figure()\n",
    "    plt.plot(x,fun_tilde,'-')\n",
    "    plt.plot(x,fun,':')\n",
    "    plt.legend((\"TT-rank =\"+str(max(TTrain.R))+\" approximation\",\"$f_1(x)$\"))\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$f_1(x)$\")\n",
    "    plt.grid()\n",
    "\n",
    "    print(\"compression factor=\",compress_factor)\n",
    "    print(TTrain.R)\n",
    "    print(\"relative error = \",error*100 ,\"%\")\n",
    "\n",
    "\n",
    "plot_sinusoid(f1,2,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform a parameter study of the order of the TTrain and the TTrank to see how storage and relative error behave. Suprisingly the order 2 Tensor with TT-rank 2 is already quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_list=range(2,14)\n",
    "rank_list=range(1,15)\n",
    "\n",
    "M = size(ord_list)\n",
    "N = size(rank_list)\n",
    "errors = zeros([M,N])\n",
    "compress = zeros([M,N])\n",
    "TTapprox_fun(f1,3,1, 1e-14)\n",
    "\n",
    "\n",
    "for j,rank in enumerate(rank_list):\n",
    "    for i,order in enumerate(ord_list):\n",
    "        res = TTapprox_fun(f1,order,rank, 1e-14)\n",
    "        errors[i,j]=res[0]\n",
    "        compress[i,j]=res[1]\n",
    "\n",
    "        \n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "for e,err in enumerate(errors.T[::2]):\n",
    "    plt.semilogy(ord_list, err, label=\"TTrank=%d\"%rank_list[2*e])\n",
    "    \n",
    "# plt.semilogy(ord_list,errors[:,0],'x--')\n",
    "# plt.semilogy(ord_list,errors[:,1],'o-')\n",
    "# plt.semilogy(ord_list,errors[:,3],':+')\n",
    "# plt.plot(ord_list,errors[:,-1],':*')\n",
    "plt.legend() # (['TTrank='+str(rank_list[0]),\"TTrank=\"+str(rank_list[1]),\"TTrank=\"+str(rank_list[3]),\"TTrank=\"+str(rank_list[-1])])\n",
    "plt.xlabel(\"order\")\n",
    "plt.ylabel(\"rel error\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "for e,cprs in enumerate(compress.T[::2]):\n",
    "    plt.semilogy(ord_list, cprs, label=\"TTrank=%d\"%rank_list[2*e])\n",
    "    \n",
    "# plt.plot(ord_list,compress[:,0],'x--')\n",
    "# plt.plot(ord_list,compress[:,1],'o-')\n",
    "# plt.plot(ord_list,compress[:,3],':+')\n",
    "# plt.plot(ord_list,compress[:,-1],':*')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.legend(['TTrank='+str(rank_list[0]),\"TTrank=\"+str(rank_list[1]),\"TTrank=\"+str(rank_list[3]),\"TTrank=\"+str(rank_list[-1])])\n",
    "plt.xlabel(\"order\")\n",
    "plt.ylabel(\"compression rate\")\n",
    "# plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Detection of self similar structures with noise\n",
    "\n",
    "\\begin{definition}[Self similar]\\label{def:self_sim}\n",
    "   $A$ is a self-similar set, if it is the invariant set (attractor) of an Iterated function system {$f_i, i=1\\dots,m$}:\n",
    "   \n",
    "   \\begin{align*}\n",
    "     A={\\bigcup _{i=1}^m} f_i(A)\n",
    "    \\end{align*}\n",
    "\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "Construct a self similar function from $g(x)=$rect$(x-7)$:\n",
    "\n",
    "\\begin{equation}\\label{eq:sel}\n",
    "    f(x)=2000\\sum_{k=0}^N\\frac{g(x/(1.5)^k)}{(1.5)^k}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Data series\n",
    "Nx= 2**14\n",
    "x = linspace(0,8,Nx)\n",
    "\n",
    "def rect(x):\n",
    "    return heaviside(x-6.5,1)-heaviside(x-7.5,1)\n",
    "\n",
    "data = 0*x\n",
    "for k in range(0,10):\n",
    "    data+=rect(x*1.5**k)/1.5**k\n",
    "\n",
    "data*=2000\n",
    "\n",
    "plt.plot(x,data)\n",
    "plt.plot(x,2000*rect(x))\n",
    "plt.legend((\"f(x)\",'$\\sim$rect$(x)$'))\n",
    "plt.ylabel(\"$f(x)$\")\n",
    "plt.xlabel(\"x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modulate a random noise on the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data + (1-2*np.random.rand(size(data)))\n",
    "data10 = data + 100*(1-2*np.random.rand(size(data)))\n",
    "plt.plot(data)\n",
    "plt.plot(data1,\"*\")\n",
    "plt.plot(data10,'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=13\n",
    "rank_list=range(1,150)\n",
    "err_eucl=np.zeros([3,size(rank_list)])\n",
    "compress=np.zeros([3,size(rank_list)])\n",
    "err_frob=np.zeros([3,size(rank_list)])\n",
    "ftilde=[]\n",
    "\n",
    "for i,rank in enumerate(rank_list):\n",
    "    \n",
    "    # results for no noise\n",
    "    res = TTapprox_fun(data,order,rank, 1e-14)\n",
    "    err_eucl[0,i]=res[0]\n",
    "    err_frob[0,i]=res[-1]\n",
    "    compress[0,i]=res[1]\n",
    "        \n",
    "    # noise amplitude 1\n",
    "    res = TTapprox_fun(data1,order,rank, 1e-14, data)  # self similarity --> noise is large in small strctures and cannot be cut off by HSVD\n",
    "    err_eucl[1,i]=res[0]\n",
    "    err_frob[1,i]=res[-1]\n",
    "    compress[1,i]=res[1]\n",
    "        \n",
    "    #noise amplitude 10\n",
    "    res = TTapprox_fun(data10,order,rank, 1e-14, data)\n",
    "    err_eucl[2,i]=res[0]\n",
    "    err_frob[2,i]=res[-1]\n",
    "    compress[2,i]=res[1]\n",
    "    \n",
    "plt.semilogy(rank_list,err_eucl[0,:])\n",
    "plt.semilogy(rank_list,err_eucl[1,:])\n",
    "plt.semilogy(rank_list,err_eucl[2,:])\n",
    "plt.xlabel(\"TTrank\")\n",
    "plt.ylabel(\"rel euclidean error\")\n",
    "plt.legend([\"original\",\"noise amplitude 1\",\"noise amplitude 10\"])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(size(compress,0)):\n",
    "    plt.loglog(err_frob[i,:],compress[i,:])\n",
    "plt.legend([\"original\",\"noise amplitude 1\",\"noise amplitude 10\"])\n",
    "plt.xlabel(\"rel frob norm\")\n",
    "plt.ylabel(\"compression factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results for TTrank=2 and 4\n",
    "\n",
    "res = TTapprox_fun(data10,order,2, 1e-14)\n",
    "plt.plot(x,data10)\n",
    "plt.plot(x,res[3],':')\n",
    "res = TTapprox_fun(data10,order,4, 1e-14)\n",
    "plt.plot(x,res[3],'--')\n",
    "res = TTapprox_fun(data10,order,10, 1e-14)\n",
    "plt.plot(x,res[3],'--')\n",
    "plt.legend([\"original\",\"rank 2\",\"rank 4\",\"rank 10\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(<a id=\"cit-LarK2017\" href=\"#call-LarK2017\">von Larcher and Klein, 2017</a>) von Larcher Thomas and Klein Rupert, ``_On identification of self-similar characteristics using the Tensor Train decomposition method with application to channel turbulence flow_'', arXiv preprint arXiv:1708.07780, vol. , number , pp. ,  2017.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "author": "m",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}